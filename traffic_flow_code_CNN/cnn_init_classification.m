function net = cnn_init_classification(opts)
%

rng('default');
rng(0);
% input size = 10x20x3
% constant scalar for the random initial network weights. 
f=1/100; 

bias = 0.01;
net.layers = {} ;
pooling_type = 'max'; % was 'max'
nb_filters = [64;128;256;7]; %[32;64;128;7];
net.layers{end+1} = struct('type', 'conv', ... was 32 filters
                           'weights', {{f*randn(2,2,1,nb_filters(1), 'single'), zeros(1, nb_filters(1), 'single')}}, ... % was (2,4,3
                           'biases', bias*ones(1, 32, 'single'), ...
                           'stride', 1, ...
                           'pad', 0, ...
                           'filtersLearningRate', 1, ...
                           'biasesLearningRate', 2, ...
                           'filtersWeightDecay', 1, ...
                           'biasesWeightDecay', 0, ...
                           'name', 'conv1') ;               %give us res(2)
net.layers{end+1} = struct('type', 'relu') ;                %res(3)              
net.layers{end+1} = struct('type', 'pool', ...
                           'method', pooling_type, ... %choice = pooling_type, 'avg'
                           'pool', [2 2], ...
                           'stride', 2, ...
                           'pad', 0) ; %[7 7] st=7   %res(4)

%% -------------------------------                       
 net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {{f*randn(2,2,nb_filters(1),nb_filters(2), 'single'), zeros(1, nb_filters(2), 'single')}}, ... % was (2,4
                           'biases', bias*ones(1,nb_filters(2),'single'), ...
                           'stride', 1, ...
                           'pad', 0, ...
                           'filtersLearningRate', 1, ...
                           'biasesLearningRate', 2, ...
                           'filtersWeightDecay', 1, ...
                           'biasesWeightDecay', 0, ...
                           'name', 'conv2') ;   %res(5)
net.layers{end+1} = struct('type', 'relu') ;   %res(6)                                          
net.layers{end+1} = struct('type', 'pool', ...
                           'method', pooling_type, ... %choice = pooling_type, 'avg'
                           'pool', [2 2], ...
                           'stride', 2, ...
                           'pad', 0) ;  %res(7)
%% -------------------------------        
net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {{f*randn(1,4,nb_filters(2),nb_filters(3), 'single'), zeros(1, nb_filters(3), 'single')}}, ... % was (1,4
                           'biases', bias*ones(1,nb_filters(3),'single'), ...
                           'stride', 1, ...
                           'pad', 0, ...
                           'filtersLearningRate', 1, ...
                           'biasesLearningRate', 2, ...
                           'filtersWeightDecay', 1, ...
                           'biasesWeightDecay', 0, ...
                           'name', 'fc1') ;                 %res(8)
net.layers{end+1} = struct('type', 'relu') ;                %res(9)
net.layers{end + 1} = struct('type','dropout','rate',0.5); %res(10)

%% -------------------------------  
%nb_neurons_lastFC = 7;
net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {{f*randn(1,1,nb_filters(3),nb_filters(4), 'single'), zeros(1, nb_filters(4), 'single')}}, ...
                            'biases', bias*ones(1, nb_filters(4), 'single'), ...   
                            'stride', 1, ...
                           'pad', 0, ...
                           'filtersLearningRate', 1, ...
                           'biasesLearningRate', 2, ...
                           'filtersWeightDecay', 1, ...
                           'biasesWeightDecay', 0, ...
                           'name', 'fc3') ;  %res(11)
              
%% -------------------------------
nnloss_type = 'softmaxloss';
net.layers{end+1} = struct('type', nnloss_type) ; % res(13)

% %add an extra relu for regression type
% if(isequal(opts.prediction_type,'r'))
%     net.layers{end+1} = struct('type', 'relu') ;   %res(12)
% end
% % Loss layer
%     net.layers{end+1} = struct('type', nnloss_type) ; % res(13)

% Visualize the network
vl_simplenn_display(net, 'inputSize', [10 20 1 50])